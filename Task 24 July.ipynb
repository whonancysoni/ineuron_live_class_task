{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5464c933",
   "metadata": {},
   "source": [
    "We have Attribute Dataset and Dress Sales Dataset. These are connected to each other based on Dress_ID. Perform the Following Task:\n",
    "\n",
    "1.Create a Table of attribute dataset and dress dataset in mysql workbench/python\n",
    "2.Do a bulk load for these 2 tables for respective dataset in mysql workbench/python\n",
    "3.Read these datasets in pandas as a dataframe\n",
    "4.Convert Attribute Dataset in JSON Format (.to_json will be used)\n",
    "5.Store this json dataset into mongodb (Insert_many will be used)\n",
    "6.In SQL task, try to perform left join operation with Attribute dataset and dress dataset on column Dress_ID\n",
    "7.Write the SQL query to find out how many unique dress that we have based on Dress_ID\n",
    "8.Try to find out how many dress is having recommendation as 0\n",
    "9.Try to find out total dress sales for each and every Dress_ID\n",
    "10.Try to find out the third highest most selling Dress_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1 and Task 2 Done\n",
    "#MySQL Code\n",
    "show databases;\n",
    "create database task;\n",
    "use task;\n",
    "\n",
    "#Creating table for Attribute Dataset\n",
    "create table if not exists attribute_data_v1 (\n",
    "dress_id int ,\n",
    "style varchar(30) , \n",
    "price varchar(30) , \n",
    "rating decimal (2,1) ,\n",
    "size varchar(30),\n",
    "season varchar(30),\n",
    "neckline varchar(30),\n",
    "sleevelength varchar(30) , \n",
    "waiseline varchar(30) ,\n",
    "material varchar(30) , \n",
    "fabrictype varchar(30) , \n",
    "decoration varchar(30) , \n",
    "patterntype varchar(30) , \n",
    "recommendation int\n",
    ");\n",
    "\n",
    "\n",
    "#Inserting Attribute Dataset Records\n",
    "LOAD DATA INFILE '\\Attribute DataSet.csv' INTO TABLE attribute_data_v1\n",
    "FIELDS TERMINATED BY ','\n",
    "ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\r\\n'\n",
    "IGNORE 1 LINES;\n",
    "\n",
    "#Checking the data\n",
    "select * from attribute_data_v1; #Coming Properly\n",
    "\n",
    "#Creating table for Dress Sales\n",
    "create table if not exists dress_sales_v1 (\n",
    "dress_id int ,\n",
    "`29/8/2013` int , \n",
    "`31/8/2013` int , \n",
    "`2/9/2013` int ,\n",
    "`4/9/2013` int ,\n",
    "`6/9/2013` int,\n",
    "`8/9/2013` int,\n",
    "`10/9/2013` int , \n",
    "`12/9/2013` int ,\n",
    "`14/9/2013` int , \n",
    "`16/9/2013` int , \n",
    "`18/9/2013` int , \n",
    "`20/9/2013` int , \n",
    "`22/9/2013` int ,\n",
    "`24/9/2013` int ,\n",
    "`26/9/2013` int ,\n",
    "`28/9/2013` int ,\n",
    "`30/9/2013` int ,\n",
    "`2/10/2013` int ,\n",
    "`4/10/2013` int ,\n",
    "`6/10/2013` int ,\n",
    "`8/10/2013` int ,\n",
    "`10/10/2013` int ,\n",
    "`12/10/2013` int\n",
    ");\n",
    "\n",
    "#Inserting Attribute Dataset Records\n",
    "LOAD DATA INFILE '\\Dress Sales.csv' INTO TABLE dress_sales_v1\n",
    "FIELDS TERMINATED BY ','\n",
    "ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\r\\n'\n",
    "IGNORE 1 LINES;\n",
    "\n",
    "select * from dress_sales_v1 #Coming Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba08bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (8.0.29)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mysql-connector-python) (3.19.1)\n"
     ]
    }
   ],
   "source": [
    "#Task 3\n",
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46eeb25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x0000017A78C6B340>\n"
     ]
    }
   ],
   "source": [
    "#Task 3\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mydb = connection.connect(host = \"Localhost\", user = \"root\", passwd = \"Useyourpwd\", use_pure = True)\n",
    "print(mydb)\n",
    "\n",
    "#Run SQL\n",
    "sql_query1 = pd.read_sql('select * from task.attribute_data_v1', mydb)\n",
    "sql_query2 = pd.read_sql('select * from task.dress_sales_v1', mydb)\n",
    "\n",
    "\n",
    "#Convert SQL to DataFrame\n",
    "attribute_data = pd.DataFrame(sql_query1, columns = ['dress_id', 'style', 'price','rating','size','season','neckline',\n",
    "                                        'sleevelength','waiseline','material','fabrictype','decoration',\n",
    "                                        'patterntype','recommendation'])\n",
    "\n",
    "dress_sales = pd.DataFrame(sql_query2, columns = ['dress_id','29/8/2013', '31/8/2013', '2/9/2013','4/9/2013','6/9/2013','8/9/2013','10/9/2013',\n",
    "                                        '12/9/2013','14/9/2013','16/9/2013','18/9/2013','20/9/2013','22/9/2013','24/9/2013'\n",
    "                                        '24/9/2013','26/9/2013','28/9/2013','30/9/2013','2/10/2013','4/10/2013','6/10/2013',\n",
    "                                        '8/10/2013','10/10/2013','12/10/2013'])\n",
    "\n",
    "\n",
    "print(attribute_data) #Coming Correctly\n",
    "print(dress_sales) #Coming Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10215b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4\n",
    "#Converting Attribute Dataset dataframe into json\n",
    "attribute_data_json = attribute_data.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fedd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5\n",
    "#Storing JSON into MongoDB\n",
    "import pymongo\n",
    "import json\n",
    "from pymongo import MongoClient, InsertOne\n",
    "client = pymongo.MongoClient(\"mongodb+srv://gauravratan:useyourpwd@cluster0.hunum.mongodb.net/?retryWrites=true&w=majority\") #Connectivity between python and MongoDB\n",
    "db2 = client.test\n",
    "\n",
    "#Creating Database\n",
    "database = client['Task']\n",
    "#Creating Collection/Document inside Database (Same as creating Tables inside Database in SQL Systems)\n",
    "collection = database[\"Json\"]\n",
    "#Replacing single quotes with double quotes on attribute_data_json to make it valid json\n",
    "\n",
    "print(attribute_data_json)\n",
    "\n",
    "#Storing JSON Data into MongoDB\n",
    "#Loading or Opening the json file\n",
    "with open(r'C:\\Users\\kiit\\PycharmProjects\\Class 21_24th July 2022_Task\\attribute_data.json') as file:\n",
    "    file_data = json.load(file)\n",
    "\n",
    "# Inserting the loaded data in the Collection\n",
    "# if JSON contains data more than one entry\n",
    "# insert_many is used else insert_one is used\n",
    "\n",
    "if isinstance(file_data, list):\n",
    "    collection.insert_many(file_data)\n",
    "else:\n",
    "    collection.insert_one(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2e0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 6\n",
    "#Left Join with Attribute Dataset and Dress Sales Dataset\n",
    "\n",
    "joined_data = pd.merge(attribute_data,dress_sales,how = 'left',on = 'dress_id')\n",
    "print(joined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6f3bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 7\n",
    "#Write the SQL query to find out how many unique dress that we have based on Dress_ID\n",
    "import mysql.connector as connection\n",
    "mydb = connection.connect(host = \"Localhost\", user = \"root\", passwd = \"Useyourpwd\", use_pure = True)\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\"select count(distinct(dress_id)) from task.attribute_data_v1\")\n",
    "for i in cursor.fetchall():\n",
    "  print(i) #Gives answer (475,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a220f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 8\n",
    "#Try to find out how many dress is having recommendation as 0\n",
    "print((attribute_data.recommendation == 0).sum())  #290 such values. In SQL we can write: select count(*) from table name where recommendation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bdd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 9\n",
    "#Find the total sales for each and every dress id\n",
    "#Creating Column Total Sales for each Dress ID\n",
    "dress_sales['Sales'] = dress_sales[['29/8/2013', '31/8/2013', '2/9/2013','4/9/2013','6/9/2013','8/9/2013','10/9/2013',\n",
    "                                        '12/9/2013','14/9/2013','16/9/2013','18/9/2013','20/9/2013','22/9/2013','24/9/2013'\n",
    "                                        ,'26/9/2013','28/9/2013','30/9/2013','2/10/2013','4/10/2013','6/10/2013',\n",
    "                                        '8/10/2013','10/10/2013','12/10/2013']].agg('sum', axis=1)\n",
    "\n",
    "#Rolling up at Unique Dress Id Level\n",
    "print(dress_sales.groupby('dress_id')['Sales'].sum()) #This will provide the rolled up sum of sales of each unique dress_id. Similarily we can do in SQL also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 10\n",
    "#Try to find out the third highest most selling Dress_ID\n",
    "sales_data = dress_sales.groupby('dress_id')['Sales'].sum().reset_index().rename(columns={'sum':'Sales','dress_id' : 'dress_id'})\n",
    "print(sales_data)\n",
    "print(sales_data.Sales.nlargest(3).iloc[-1]) #Getting 75979 as 3rd largest sum\n",
    "\n",
    "#If we have to do in SQL then query will be\n",
    "SELECT DISTINCT SALES AS 3RDHighestSales\n",
    "FROM DRESS_SALES_TABLE\n",
    "ORDER BY SALES DESC\n",
    "LIMIT 1 \n",
    "OFFSET 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf4eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
